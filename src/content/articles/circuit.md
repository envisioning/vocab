---
title: Circuit
summary: A structured arrangement of computational or logical elements and their connections that implements, represents, or constrains computation in hardware or learned models.
slug: circuit
---

In AI contexts, a circuit describes an organized set of processing units (gates, neurons, attention heads, channels, or other primitives) and their interconnections that together implement a computation or functional transformation; the term spans physical electronic/logical circuits, formal Boolean/circuit-complexity models, and emergent subnetworks or motifs inside neural architectures that realize particular features or algorithms. Thinking in terms of circuits provides a compact abstraction for reasoning about capacity, depth, parallelism, and compositionality: Boolean circuits and computational graphs give formal lenses for complexity and resource bounds, while the modern notion of neural “circuits” used in mechanistic interpretability treats pathways of activations and weights as algorithmic modules that can be identified, probed, intervened upon, and recomposed. Practically, circuit-level analysis enables causal interventions (ablation, activation patching, causal mediation), targeted editing and distillation, diagnosis of failure modes, and the design of modular architectures; theoretically it connects ML behavior to classical results in circuit complexity, information flow, and dynamical systems, informing how representational primitives and inductive biases map to implementable computations.

First formal uses of “circuit” trace to electrical-switching and Boolean analyses in the 1930s–1950s (e.g., Claude Shannon’s work on switching circuits), with circuit models and circuit complexity crystallizing mid-20th century; the specific framing of internal neural-network “circuits” as interpretability targets became prominent in the ML community in the late 2010s–early 2020s alongside mechanistic-interpretability research that sought to identify and describe subnetworks implementing features or algorithms.

Key contributors include early foundations in switching theory and computing (Claude Shannon, John von Neumann), the circuit-complexity community (e.g., Andrew Yao, Leslie Valiant) and foundational neuroscience and neural-network pioneers (Santiago Ramón y Cajal, Alan Hodgkin & Andrew Huxley, John Hopfield). In the AI interpretability era, the mechanistic-interpretability and visualization communities (notably work by Chris Olah and collaborators and groups at OpenAI, Distill and similar academic and industry labs, as well as researchers at Anthropic and allied academic groups) have driven the popularization and methodology for discovering and characterizing circuits inside modern deep models.