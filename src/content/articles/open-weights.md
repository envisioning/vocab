---
generality:
- 0.72
- 0.71
- 0.7
- 0.69
- 0.68
- 0.67
- 0.66
slug: open-weights
summary: Access to model parameters of AI/ML systems, enabling transparency and collaboration in development and research.
title: Open Weights
---

Open Weights refer to the practice of making the learned parameters of AI models, particularly neural networks, available to the public for inspection, use, or further development. This openness allows researchers and developers to build upon existing models, ensuring reproducibility of results, aiding in the verification of AI claims, and facilitating the training of new models with optimized weights. Sharing open weights encourages collaboration across the AI community by reducing the resources and time required to replicate and enhance state-of-the-art systems. This practice has become instrumental in democratizing AI research, promoting ethical AI development, and fostering innovation, as it enables a broader spectrum of contributors to engage with advanced AI technologies.

The term "Open Weights" emerged prominently in the mid-2010s as deep learning models began to proliferate and researchers recognized the benefits of sharing model parameters for acceleration of advances in AI research and deployment.

Key contributors to the development and promotion of Open Weights include AI research giants like Google, with their open-sourcing of models like BERT, and organizations like OpenAI, which advocate for transparency in AI and regularly release their model weights as part of their commitment to literature and community growth.