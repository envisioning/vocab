{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yt api docs:\n",
    "- https://developers.google.com/youtube/v3/quickstart/python\n",
    "- https://developers.google.com/resources/api-libraries/documentation/youtube/v3/python/latest/youtube_v3.search.html\n",
    "- https://developers.google.com/youtube/v3/getting-started#quota "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Current directory: /Users/kemi/Documents/GitHub/vocab/src/scripts\n",
      "INFO:__main__:Root directory: /Users/kemi/Documents/GitHub/vocab\n",
      "INFO:__main__:Articles path: /Users/kemi/Documents/GitHub/vocab/src/content/articles\n",
      "INFO:__main__:Output path: /Users/kemi/Documents/GitHub/vocab/src/data/youtube-video-list.json\n",
      "INFO:__main__:Config path: /Users/kemi/Documents/GitHub/vocab/src/scripts/components-generator/config.py\n",
      "INFO:googleapiclient.discovery_cache:file_cache is only supported with oauth2client<4.0.0\n",
      "INFO:__main__:Processed autoformalization\n",
      "INFO:__main__:Processed autograd\n",
      "INFO:__main__:Processed automaton\n",
      "INFO:__main__:Processed automl-automated-machine-learning\n",
      "INFO:__main__:Processed autonomous-agents\n",
      "INFO:__main__:Results saved to /Users/kemi/Documents/GitHub/vocab/src/data/youtube-video-list.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import yaml\n",
    "from typing import Dict, List, Set\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "# Handle path resolution for notebook environment\n",
    "current_dir = os.getcwd()\n",
    "ROOT_DIR = os.path.abspath(os.path.join(current_dir, \"../..\"))\n",
    "ARTICLES_PATH = os.path.join(ROOT_DIR, \"src/content/articles\")\n",
    "OUTPUT_PATH = os.path.join(ROOT_DIR, \"src/data/youtube-video-list.json\")\n",
    "CONFIG_PATH = os.path.join(ROOT_DIR, \"src/scripts/components-generator/config.py\")\n",
    "\n",
    "# Print paths for debugging\n",
    "logger.info(f\"Current directory: {current_dir}\")\n",
    "logger.info(f\"Root directory: {ROOT_DIR}\")\n",
    "logger.info(f\"Articles path: {ARTICLES_PATH}\")\n",
    "logger.info(f\"Output path: {OUTPUT_PATH}\")\n",
    "logger.info(f\"Config path: {CONFIG_PATH}\")\n",
    "\n",
    "def setup_youtube_client(api_key: str):\n",
    "    \"\"\"Initialize YouTube API client.\"\"\"\n",
    "    try:\n",
    "        return build('youtube', 'v3', developerKey=api_key)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize YouTube client: {e}\")\n",
    "        raise\n",
    "\n",
    "def search_videos(youtube_client, title: str) -> List[Dict]:\n",
    "    \"\"\"Search for YouTube videos related to a concept.\"\"\"\n",
    "    try:\n",
    "        # Build search query\n",
    "        search_query = f\"'{title}' in AI or machine learning -tutorial -howto\"\n",
    "        \n",
    "        request = youtube_client.search().list(\n",
    "            q=search_query,\n",
    "            part='snippet',\n",
    "            maxResults=5,\n",
    "            type='video',\n",
    "            videoCaption='closedCaption', # With captions for accessibility\n",
    "            order='relevance',           # Most relevant first\n",
    "            safeSearch='strict'          # Educational content\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        videos = [\n",
    "            {\n",
    "                'title': item['snippet']['title'],\n",
    "                'link': f\"https://www.youtube.com/watch?v={item['id']['videoId']}\"\n",
    "            }\n",
    "            for item in response.get('items', [])\n",
    "        ]\n",
    "        \n",
    "        return videos\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to search videos for {title}: {e}\")\n",
    "        return []\n",
    "\n",
    "def load_existing_data() -> tuple[List[Dict], Set[str]]:\n",
    "    \"\"\"Load existing JSON data and processed slugs.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(OUTPUT_PATH):\n",
    "            with open(OUTPUT_PATH, 'r', encoding='utf-8') as f:\n",
    "                existing_data = json.load(f)\n",
    "                processed_slugs = {item['slug'] for item in existing_data}\n",
    "                return existing_data, processed_slugs\n",
    "        return [], set()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading existing data: {e}\")\n",
    "        return [], set()\n",
    "\n",
    "def parse_frontmatter(file_path: str) -> Dict:\n",
    "    \"\"\"Parse frontmatter from markdown file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "            if content.startswith('---'):\n",
    "                # Find the second '---' that closes the frontmatter\n",
    "                _, fm, _ = content.split('---', 2)\n",
    "                return yaml.safe_load(fm)\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error parsing frontmatter from {file_path}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def get_unprocessed_files(processed_slugs: Set[str]) -> List[str]:\n",
    "    \"\"\"Get list of unprocessed markdown files.\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(ARTICLES_PATH):\n",
    "            logger.error(f\"Articles directory not found: {ARTICLES_PATH}\")\n",
    "            return []\n",
    "\n",
    "        all_files = [f for f in os.listdir(ARTICLES_PATH) if f.endswith('.md')]\n",
    "        all_files.sort()\n",
    "        \n",
    "        unprocessed_files = []\n",
    "        for file in all_files:\n",
    "            file_path = os.path.join(ARTICLES_PATH, file)\n",
    "            try:\n",
    "                frontmatter = parse_frontmatter(file_path)\n",
    "                if frontmatter.get('slug') not in processed_slugs:\n",
    "                    unprocessed_files.append(file_path)\n",
    "                    if len(unprocessed_files) >= BATCH_SIZE:\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error reading file {file}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        return unprocessed_files\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error scanning directory: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_files(youtube_client, files: List[str]) -> List[Dict]:\n",
    "    \"\"\"Process markdown files and get video recommendations.\"\"\"\n",
    "    results = []\n",
    "    had_errors = False\n",
    "    \n",
    "    for file_path in files:\n",
    "        try:\n",
    "            frontmatter = parse_frontmatter(file_path)\n",
    "            title = frontmatter.get('title', '')\n",
    "            slug = frontmatter.get('slug', '')\n",
    "            \n",
    "            if not title or not slug:\n",
    "                continue\n",
    "                \n",
    "            videos = search_videos(youtube_client, title)\n",
    "            \n",
    "            # Check if video retrieval failed\n",
    "            if not videos:\n",
    "                had_errors = True\n",
    "                logger.error(f\"No videos retrieved for {slug}, skipping save\")\n",
    "                continue\n",
    "                \n",
    "            # Only include slug and recommendations in the result\n",
    "            result = {\n",
    "                'slug': slug,\n",
    "                'recommendations': videos\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            logger.info(f\"Processed {slug}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            had_errors = True\n",
    "            logger.error(f\"Error processing file {file_path}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    # Return both results and error status\n",
    "    return results, had_errors\n",
    "\n",
    "def save_results(all_results: List[Dict]) -> None:\n",
    "    \"\"\"Save results to JSON file.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "        with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "        logger.info(f\"Results saved to {OUTPUT_PATH}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving results: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        # Load API key\n",
    "        try:\n",
    "            config_dir = os.path.dirname(CONFIG_PATH)\n",
    "            if config_dir not in sys.path:\n",
    "                sys.path.append(config_dir)\n",
    "            from config import GOOGLECLOUD_API_KEY\n",
    "        except ImportError:\n",
    "            logger.error(\"Could not import GOOGLECLOUD_API_KEY from config.py\")\n",
    "            logger.error(f\"Make sure config.py exists at: {CONFIG_PATH}\")\n",
    "            return\n",
    "        \n",
    "        youtube_client = setup_youtube_client(GOOGLECLOUD_API_KEY)\n",
    "        \n",
    "        # Load existing data\n",
    "        existing_data, processed_slugs = load_existing_data()\n",
    "        \n",
    "        # Get unprocessed files\n",
    "        files_to_process = get_unprocessed_files(processed_slugs)\n",
    "        \n",
    "        if not files_to_process:\n",
    "            logger.info(\"No new files to process\")\n",
    "            return\n",
    "            \n",
    "        # Process files\n",
    "        new_results, had_errors = process_files(youtube_client, files_to_process)\n",
    "        \n",
    "        # Only save if there were no errors\n",
    "        if not had_errors and new_results:\n",
    "            # Combine results\n",
    "            all_results = existing_data + new_results\n",
    "            \n",
    "            # Save results\n",
    "            save_results(all_results)\n",
    "        else:\n",
    "            logger.warning(\"Not saving results due to errors in video retrieval\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred in main execution: {e}\")\n",
    "        raise\n",
    "\n",
    "# Run main function when the notebook cell is executed\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
