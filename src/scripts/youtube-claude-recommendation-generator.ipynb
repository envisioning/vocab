{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file path: .../vocab/src/scripts/youtube-recommendation-generator.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Constants\u001b[39;00m\n\u001b[1;32m     14\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m---> 15\u001b[0m ROOT_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../..\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     16\u001b[0m ARTICLES_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc/content/articles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m OUTPUT_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc/data/youtube-video-list.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import frontmatter\n",
    "from typing import Dict, List, Set\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "# Handle path resolution for both notebook and script contexts\n",
    "try:\n",
    "    # When running as a script\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    # When running in Jupyter notebook\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "# Define paths relative to the current directory\n",
    "ROOT_DIR = os.path.abspath(os.path.join(current_dir, \"../..\"))\n",
    "ARTICLES_PATH = os.path.join(ROOT_DIR, \"src/content/articles\")\n",
    "OUTPUT_PATH = os.path.join(ROOT_DIR, \"src/data/youtube-video-list.json\")\n",
    "\n",
    "# Print paths for debugging\n",
    "logger.info(f\"Current directory: {current_dir}\")\n",
    "logger.info(f\"Root directory: {ROOT_DIR}\")\n",
    "logger.info(f\"Articles path: {ARTICLES_PATH}\")\n",
    "logger.info(f\"Output path: {OUTPUT_PATH}\")\n",
    "\n",
    "def setup_youtube_client(api_key: str):\n",
    "    \"\"\"Initialize YouTube API client.\"\"\"\n",
    "    try:\n",
    "        return build('youtube', 'v3', developerKey=api_key)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize YouTube client: {e}\")\n",
    "        raise\n",
    "\n",
    "def search_videos(youtube_client, concept: str) -> List[Dict]:\n",
    "    \"\"\"Search for YouTube videos related to a concept.\"\"\"\n",
    "    try:\n",
    "        # Build search query with AI/ML context\n",
    "        search_query = f\"{concept} in AI or machine learning\"\n",
    "        \n",
    "        request = youtube_client.search().list(\n",
    "            q=search_query,\n",
    "            part='snippet',\n",
    "            maxResults=3,  # Limit to top 3 results\n",
    "            type='video',\n",
    "            order='relevance'\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        # Format the response\n",
    "        videos = []\n",
    "        for item in response.get('items', []):\n",
    "            video = {\n",
    "                'title': item['snippet']['title'],\n",
    "                'link': f\"https://www.youtube.com/watch?v={item['id']['videoId']}\"\n",
    "            }\n",
    "            videos.append(video)\n",
    "        \n",
    "        return videos\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to search videos for {concept}: {e}\")\n",
    "        return []\n",
    "\n",
    "def load_existing_data() -> tuple[List[Dict], Set[str]]:\n",
    "    \"\"\"Load existing JSON data and processed slugs.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(OUTPUT_PATH):\n",
    "            with open(OUTPUT_PATH, 'r', encoding='utf-8') as f:\n",
    "                existing_data = json.load(f)\n",
    "                processed_slugs = {item['slug'] for item in existing_data}\n",
    "                return existing_data, processed_slugs\n",
    "        return [], set()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading existing data: {e}\")\n",
    "        return [], set()\n",
    "\n",
    "def get_unprocessed_files(processed_slugs: Set[str]) -> List[str]:\n",
    "    \"\"\"Get list of unprocessed markdown files.\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(ARTICLES_PATH):\n",
    "            logger.error(f\"Articles directory not found: {ARTICLES_PATH}\")\n",
    "            return []\n",
    "\n",
    "        all_files = [f for f in os.listdir(ARTICLES_PATH) if f.endswith('.md')]\n",
    "        all_files.sort()  # Ensure consistent ordering\n",
    "        \n",
    "        unprocessed_files = []\n",
    "        for file in all_files:\n",
    "            file_path = os.path.join(ARTICLES_PATH, file)\n",
    "            try:\n",
    "                post = frontmatter.load(file_path)\n",
    "                if post.get('slug') not in processed_slugs:\n",
    "                    unprocessed_files.append(file_path)\n",
    "                    if len(unprocessed_files) >= BATCH_SIZE:\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error reading file {file}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        return unprocessed_files\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error scanning directory: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_files(youtube_client, files: List[str]) -> List[Dict]:\n",
    "    \"\"\"Process markdown files and get video recommendations.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for file_path in files:\n",
    "        try:\n",
    "            # Parse markdown file\n",
    "            post = frontmatter.load(file_path)\n",
    "            title = post.get('title', '')\n",
    "            slug = post.get('slug', '')\n",
    "            \n",
    "            if not title or not slug:\n",
    "                continue\n",
    "                \n",
    "            # Get video recommendations\n",
    "            videos = search_videos(youtube_client, title)\n",
    "            \n",
    "            # Create result entry\n",
    "            result = {\n",
    "                'slug': slug,\n",
    "                'title': title,\n",
    "                'recommendations': videos\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            logger.info(f\"Processed {slug}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing file {file_path}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    return results\n",
    "\n",
    "def save_results(all_results: List[Dict]) -> None:\n",
    "    \"\"\"Save results to JSON file.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "        with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "        logger.info(f\"Results saved to {OUTPUT_PATH}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving results: {e}\")\n",
    "        # Try backup location\n",
    "        backup_path = 'youtube-video-list.json'\n",
    "        try:\n",
    "            with open(backup_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "            logger.info(f\"Results saved to backup location: {backup_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving to backup location: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        # Load API key (you'll need to implement this)\n",
    "        try:\n",
    "            from config import GOOGLECLOUD_API_KEY\n",
    "        except ImportError:\n",
    "            logger.error(\"Could not import GOOGLECLOUD_API_KEY from config.py\")\n",
    "            return\n",
    "        \n",
    "        youtube_client = setup_youtube_client(GOOGLECLOUD_API_KEY)\n",
    "        \n",
    "        # Load existing data\n",
    "        existing_data, processed_slugs = load_existing_data()\n",
    "        \n",
    "        # Get unprocessed files\n",
    "        files_to_process = get_unprocessed_files(processed_slugs)\n",
    "        \n",
    "        if not files_to_process:\n",
    "            logger.info(\"No new files to process\")\n",
    "            return\n",
    "            \n",
    "        # Process files\n",
    "        new_results = process_files(youtube_client, files_to_process)\n",
    "        \n",
    "        # Combine results\n",
    "        all_results = existing_data + new_results\n",
    "        \n",
    "        # Save results\n",
    "        save_results(all_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred in main execution: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
