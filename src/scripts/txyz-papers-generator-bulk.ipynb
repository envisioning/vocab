{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Get the absolute path of the current notebook directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# Navigate to the config directory (going up two levels from scripts/notebook to src)\n",
    "config_path = os.path.join(notebook_dir, \"components-generator\")\n",
    "sys.path.append(config_path)\n",
    "from config import TXYZ_API_KEY\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants with relative paths from vocab root\n",
    "ROOT_DIR = os.path.abspath(os.path.join(current_dir, \"../..\"))\n",
    "ARTICLES_PATH = os.path.join(ROOT_DIR, \"src/content/articles\")\n",
    "OUTPUT_PATH = os.path.join(ROOT_DIR, \"src/data/txyz-papers.json\")\n",
    "API_URL = \"https://api.txyz.ai/v1/search/scholar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing_results():\n",
    "    \"\"\"Load existing results and extract processed slugs.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(OUTPUT_PATH):\n",
    "            with open(OUTPUT_PATH, 'r', encoding='utf-8') as f:\n",
    "                existing_results = json.load(f)\n",
    "            processed_slugs = {item['slug'] for item in existing_results}\n",
    "            return existing_results, processed_slugs\n",
    "        return [], set()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading existing results: {str(e)}\")\n",
    "        return [], set()\n",
    "\n",
    "def get_next_unprocessed_files(processed_slugs, n=1000):\n",
    "    \"\"\"\n",
    "    Get next n unprocessed markdown files. If n is greater than remaining files,\n",
    "    process all remaining files.\n",
    "    \n",
    "    Args:\n",
    "        processed_slugs (set): Set of already processed slugs\n",
    "        n (int): Number of files to process, defaults to 5\n",
    "        \n",
    "    Returns:\n",
    "        list: List of file paths to process\n",
    "        int: Total number of remaining unprocessed files\n",
    "    \"\"\"\n",
    "    try:\n",
    "        files_to_process = []\n",
    "        remaining_count = 0\n",
    "        \n",
    "        # First count total remaining files\n",
    "        for file in sorted(os.listdir(ARTICLES_PATH)):\n",
    "            if not file.endswith('.md'):\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(ARTICLES_PATH, file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    for line in content.split('\\n'):\n",
    "                        if 'slug:' in line:\n",
    "                            slug = line.split('slug:')[1].strip()\n",
    "                            if slug not in processed_slugs:\n",
    "                                remaining_count += 1\n",
    "                            break\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Then get the files to process\n",
    "        for file in sorted(os.listdir(ARTICLES_PATH)):\n",
    "            if not file.endswith('.md'):\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(ARTICLES_PATH, file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    for line in content.split('\\n'):\n",
    "                        if 'slug:' in line:\n",
    "                            slug = line.split('slug:')[1].strip()\n",
    "                            if slug not in processed_slugs:\n",
    "                                files_to_process.append(file_path)\n",
    "                            break\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            if len(files_to_process) == n:\n",
    "                break\n",
    "        \n",
    "        if remaining_count < n:\n",
    "            print(f\"Note: Requested {n} files but only {remaining_count} unprocessed files remain.\")\n",
    "        \n",
    "        return files_to_process, remaining_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing directory: {str(e)}\")\n",
    "        return [], 0\n",
    "\n",
    "def get_title_and_slug(file_path):\n",
    "    \"\"\"Extract title and slug from markdown content.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            title = ''\n",
    "            slug = ''\n",
    "            for line in lines:\n",
    "                if 'title:' in line:\n",
    "                    title = line.split('title:')[1].strip()\n",
    "                elif 'slug:' in line:\n",
    "                    slug = line.split('slug:')[1].strip()\n",
    "                if title and slug:\n",
    "                    break\n",
    "        return title, slug\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {os.path.basename(file_path)}: {str(e)}\")\n",
    "        return '', ''\n",
    "\n",
    "def process_file(file_path):\n",
    "    \"\"\"Process single file and get API response.\"\"\"\n",
    "    try:\n",
    "        title, slug = get_title_and_slug(file_path)\n",
    "        if not title or not slug:\n",
    "            return {\"slug\": os.path.basename(file_path), \"error\": \"Could not extract title or slug\"}\n",
    "        \n",
    "        headers = {\"Authorization\": f\"Bearer {TXYZ_API_KEY}\"}\n",
    "        query = {\"query\": f\"most prominent papers on {title} related to AI or machine learning\"}\n",
    "        \n",
    "        response = requests.post(API_URL, headers=headers, params=query)\n",
    "        return {\"slug\": slug, \"search_results\": response.json()}\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {os.path.basename(file_path)}: {str(e)}\")\n",
    "        return {\"slug\": os.path.basename(file_path), \"error\": str(e)}\n",
    "\n",
    "def ensure_output_directory():\n",
    "    \"\"\"Ensure output directory exists with proper permissions.\"\"\"\n",
    "    try:\n",
    "        output_dir = os.path.dirname(OUTPUT_PATH)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating output directory: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    # Load existing results\n",
    "    existing_results, processed_slugs = load_existing_results()\n",
    "    print(f\"Found {len(existing_results)} previously processed files.\")\n",
    "    \n",
    "    # Check output directory\n",
    "    if not ensure_output_directory():\n",
    "        print(\"Cannot create output directory. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Get and process next batch of files\n",
    "    files_to_process, remaining_count = get_next_unprocessed_files(processed_slugs)\n",
    "    \n",
    "    if not files_to_process:\n",
    "        print(\"No new files to process.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Processing {len(files_to_process)} files. {remaining_count - len(files_to_process)} files will remain.\")\n",
    "    \n",
    "    new_results = []\n",
    "    for file_path in files_to_process:\n",
    "        try:\n",
    "            result = process_file(file_path)\n",
    "            new_results.append(result)\n",
    "            print(f\"Processed: {os.path.basename(file_path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error on file {os.path.basename(file_path)}: {str(e)}\")\n",
    "    \n",
    "    # Combine and save results\n",
    "    all_results = existing_results + new_results\n",
    "    try:\n",
    "        with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_results, f, indent=2)\n",
    "        print(f\"\\nResults saved to {OUTPUT_PATH}\")\n",
    "        print(f\"This batch: {len(new_results)} files\")\n",
    "        print(f\"Total processed: {len(all_results)}\")\n",
    "        print(f\"Remaining unprocessed: {remaining_count - len(files_to_process)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 previously processed files.\n",
      "Note: Requested 1000 files but only 920 unprocessed files remain.\n",
      "Processing 920 files. 0 files will remain.\n",
      "Processed: active-inference.md\n",
      "Processed: actor-critic-models.md\n",
      "Processed: adam-adaptive-moment-estimation.md\n",
      "Processed: adapter-layer.md\n",
      "Processed: adapter.md\n",
      "Processed: adaptive-dual-scale-denoising.md\n",
      "Processed: adaptive-problem-solving.md\n",
      "Processed: adversarial-attacks.md\n",
      "Processed: adversarial-debiasing.md\n",
      "Processed: adversarial-instructions.md\n",
      "Processed: aeo-answer-engine-optimization.md\n",
      "Processed: affective-computation.md\n",
      "Processed: agent-to-agent-interaction.md\n",
      "Processed: agent.md\n",
      "Processed: agentic-ai-systems.md\n",
      "Processed: agglomerative-clustering.md\n",
      "Processed: agi-artificial-general-intelligence.md\n",
      "Processed: ai-auditing.md\n",
      "Processed: ai-effect.md\n",
      "Processed: ai-failure-modes.md\n",
      "Processed: ai-governance.md\n",
      "Processed: ai-safety.md\n",
      "Processed: ai-watchdog.md\n",
      "Processed: ai-winter.md\n",
      "Processed: ait-algorithmic-information-theory.md\n",
      "Processed: alexnet.md\n",
      "Processed: algorithm.md\n",
      "Processed: algorithmic-bias.md\n",
      "Processed: algorithmic-probability.md\n",
      "Processed: alignment-platform.md\n",
      "Processed: alignment.md\n",
      "Processed: ami-advanced-machine-intelligence.md\n",
      "Processed: ami-ambient-intelligence.md\n",
      "Processed: ann-artificial-neural-networks.md\n",
      "Processed: anomaly-detection.md\n",
      "Processed: artefactual-autopoiesis.md\n",
      "Processed: artificial-curiosity.md\n",
      "Processed: artificial-neuron.md\n",
      "Processed: asi-artificial-super-intelligence.md\n",
      "Processed: asic-application-specific-integrated-circuit.md\n",
      "Processed: asl-ai-safety-level.md\n",
      "Processed: asr-automatic-speech-recognition.md\n",
      "Processed: assistant-model.md\n",
      "Processed: assistant.md\n",
      "Processed: association-rule.md\n",
      "Processed: ast-abstract-syntax-tree.md\n",
      "Processed: attention-block.md\n",
      "Processed: attention-masking.md\n",
      "Processed: attention-matrix.md\n",
      "Processed: attention-mechanisms.md\n",
      "Processed: attention-network.md\n",
      "Processed: attention-pattern.md\n",
      "Processed: attention-projection-matrix.md\n",
      "Processed: attention-seeking.md\n",
      "Processed: attention.md\n",
      "Processed: attestation.md\n",
      "Processed: autocomplete.md\n",
      "Processed: autoencoder.md\n",
      "Processed: autoformalization.md\n",
      "Processed: autograd.md\n",
      "Processed: automaton.md\n",
      "Processed: automl-automated-machine-learning.md\n",
      "Processed: autonomous-agents.md\n",
      "Processed: autonomous-learning.md\n",
      "Processed: autonomous-reasoning.md\n",
      "Processed: autopoiesis.md\n",
      "Processed: autoregressive-generation.md\n",
      "Processed: autoregressive-prediction.md\n",
      "Processed: autoregressive-sequence-generator.md\n",
      "Processed: autoregressive.md\n",
      "Processed: av-autonomous-vehicles.md\n",
      "Processed: backpropagation.md\n",
      "Processed: bagging.md\n",
      "Processed: base-model.md\n",
      "Processed: bayesian-inference.md\n",
      "Processed: bayesian-network.md\n",
      "Processed: bayesian-optimization.md\n",
      "Processed: bci-brain-computer-interface.md\n",
      "Processed: bellman-equation.md\n",
      "Processed: benchmark.md\n",
      "Processed: bert-bidirectional-encoder-representations-from-transformers.md\n",
      "Processed: best-of-n.md\n",
      "Processed: bgpt-byte-level-transformer.md\n",
      "Processed: bias-variance-curve.md\n",
      "Processed: bias-variance-dilemma.md\n",
      "Processed: bias-variance-trade-off.md\n",
      "Processed: bias.md\n",
      "Processed: biocomputer.md\n",
      "Processed: biomarkers.md\n",
      "Processed: black-box-problem.md\n",
      "Processed: black-box.md\n",
      "Processed: blind-alley.md\n",
      "Processed: bnn-bispectral-neural-networks.md\n",
      "Processed: bnns-biological-neural-networks.md\n",
      "Processed: boltzmann-machine.md\n",
      "Processed: boolean.md\n",
      "Processed: boosting.md\n",
      "Processed: bow-bag-of-words.md\n",
      "Processed: bql-binary-quantization-learning.md\n",
      "Processed: brain-organoid-reservoir-computing.md\n",
      "Processed: brainoware.md\n",
      "Processed: branching-factor.md\n",
      "Processed: brute-force.md\n",
      "Processed: byte-level-state-space.md\n",
      "Processed: c2pa-coalition-for-content-provenance-and-authenticity.md\n",
      "Processed: capability-control.md\n",
      "Processed: capability-ladder.md\n",
      "Processed: capsule-networks.md\n",
      "Processed: catastrophic-forgetting.md\n",
      "Processed: categorical-deep-learning.md\n",
      "Processed: causal-ai.md\n",
      "Processed: causal-inference.md\n",
      "Processed: causal-transformer.md\n",
      "Processed: cd-contrastive-divergence.md\n",
      "Processed: centaur.md\n",
      "Processed: cerebral-organoids.md\n",
      "Processed: chatbot.md\n",
      "Processed: cherry-picking.md\n",
      "Processed: chinchilla-scaling.md\n",
      "Processed: chinese-room.md\n",
      "Processed: chunking-strategy.md\n",
      "Processed: chunking.md\n",
      "Processed: church-encoding.md\n",
      "Processed: church-turing-thesis.md\n",
      "Processed: clanker.md\n",
      "Processed: classification.md\n",
      "Processed: classifier.md\n",
      "Processed: cli-command-line-interface.md\n",
      "Processed: clip-contrastive-languageimage-pre-training.md\n",
      "Processed: clustering.md\n",
      "Processed: cnn-convolutional-neural-network.md\n",
      "Processed: co-pilot.md\n",
      "Processed: cognitive-architecture.md\n",
      "Processed: cognitive-computing.md\n",
      "Processed: cognitive-flexibility.md\n",
      "Processed: collaborative-intelligence.md\n",
      "Processed: comparative-advantage.md\n",
      "Processed: complex-interaction.md\n",
      "Processed: composability.md\n",
      "Processed: compositional-reasoning.md\n",
      "Processed: computational-creativity.md\n",
      "Processed: compute-efficiency.md\n",
      "Processed: compute.md\n",
      "Processed: computronium-maximizer.md\n",
      "Processed: conditional-generation.md\n",
      "Processed: conditional-probability.md\n",
      "Processed: confidential-computing.md\n",
      "Processed: confusion-matrix.md\n",
      "Processed: connectionist-ai.md\n",
      "Processed: consciousness-level.md\n",
      "Processed: constitutional-ai.md\n",
      "Processed: context-window.md\n",
      "Processed: contextual-bm25.md\n",
      "Processed: contextual-embedding.md\n",
      "Processed: contextual-retrieval.md\n",
      "Processed: continual-pre-training.md\n",
      "Processed: continuous-learning.md\n",
      "Processed: contrastive-learning.md\n",
      "Processed: control-logic.md\n",
      "Processed: control-problem.md\n",
      "Processed: control-vector.md\n",
      "Processed: controlnet.md\n",
      "Processed: convergence.md\n",
      "Processed: convergent-learning.md\n",
      "Processed: convolution.md\n",
      "Processed: cooperativity.md\n",
      "Processed: cosine-similarity.md\n",
      "Processed: cot-chain-of-thought.md\n",
      "Processed: counterfactual-explanations.md\n",
      "Processed: counterfactual-fairness.md\n",
      "Processed: covariance.md\n",
      "Processed: criteria-drift.md\n",
      "Processed: cross-attention.md\n",
      "Processed: cross-domain-competency.md\n",
      "Processed: cross-entropy-loss.md\n",
      "Processed: cross-validation.md\n",
      "Processed: csps-constraint-satisfaction-problems.md\n",
      "Processed: cuda-compute-unified-device-architecture.md\n",
      "Processed: curse-of-dimensionality.md\n",
      "Processed: custom-instructions.md\n",
      "Processed: cybernetics.md\n",
      "Processed: dag-directed-acyclic-graphs.md\n",
      "Processed: data-augmentation.md\n",
      "Processed: data-blending.md\n",
      "Processed: data-efficient-learning.md\n",
      "Processed: data-imputation.md\n",
      "Processed: data-mining.md\n",
      "Processed: data-wall.md\n",
      "Processed: dataset.md\n",
      "Processed: dbn-deep-belief-network.md\n",
      "Processed: de-biasing.md\n",
      "Processed: decidability.md\n",
      "Processed: decision-tree.md\n",
      "Processed: decomposition.md\n",
      "Processed: deep-ssms-deep-state-space-models.md\n",
      "Processed: deepfakes.md\n",
      "Processed: denoising-autoencoder.md\n",
      "Processed: denoising.md\n",
      "Processed: deterministic-quoting.md\n",
      "Processed: deterministic.md\n",
      "Processed: differentiable-parametric-curves.md\n",
      "Processed: differential-privacy.md\n",
      "Processed: diffusion-forcing.md\n",
      "Processed: diffusion.md\n",
      "Processed: dijkstras-algorithm.md\n",
      "Processed: dimension-returns.md\n",
      "Processed: dimension.md\n",
      "Processed: dimensionality-reduction.md\n",
      "Processed: direct-manipulation.md\n",
      "Processed: directed-evolution.md\n",
      "Processed: discontinuous-jump.md\n",
      "Processed: discount-factor.md\n",
      "Processed: discrete-state-space-model.md\n",
      "Processed: discriminative-ai.md\n",
      "Processed: discriminator.md\n",
      "Processed: distillation-method.md\n",
      "Processed: distillation.md\n",
      "Processed: dl-deep-learning.md\n",
      "Processed: dlms-deep-language-models.md\n",
      "Processed: dnc-differential-neural-computer.md\n",
      "Processed: dnn-deep-neural-networks.md\n",
      "Processed: dola-decoding-by-contrasting-layers.md\n",
      "Processed: dot-product-similarity.md\n",
      "Processed: double-descent.md\n",
      "Processed: dp-dynamic-programming.md\n",
      "Processed: dpo-direct-preference-optimization.md\n",
      "Processed: dqn-deep-q-networks.md\n",
      "Processed: drl-deep-reinforcement-learning.md\n",
      "Processed: dropout.md\n",
      "Processed: dss-decision-support-system.md\n",
      "Processed: dtw-dynamic-time-warping.md\n",
      "Processed: dual-use-foundational-model.md\n",
      "Processed: dual-use.md\n",
      "Processed: dualism.md\n",
      "Processed: early-exit-loss.md\n",
      "Processed: ebm-energy-based-model.md\n",
      "Processed: eda-exploratory-data-analysis.md\n",
      "Processed: edge-model.md\n",
      "Processed: edl-experimentation-driven-learning.md\n",
      "Processed: eeg-to-text.md\n",
      "Processed: effective-accelerationism.md\n",
      "Processed: em-expectation-maximization.md\n",
      "Processed: embedding-space.md\n",
      "Processed: embedding.md\n",
      "Processed: embodied-ai.md\n",
      "Processed: embodied-intelligence.md\n",
      "Processed: emergence.md\n",
      "Processed: emotional-integrity.md\n",
      "Processed: empathic-ai.md\n",
      "Processed: emt-extended-mind-transformer.md\n",
      "Processed: encoder-decoder-models.md\n",
      "Processed: encoder-decoder-transformer.md\n",
      "Processed: end-to-end-learning.md\n",
      "Processed: enrichment.md\n",
      "Processed: ensamble-algorithm.md\n",
      "Processed: ensemble-learning.md\n",
      "Processed: ensemble-methods.md\n",
      "Processed: epistemic-foraging.md\n",
      "Processed: equivariance.md\n",
      "Processed: ethical-ai.md\n",
      "Processed: eval-evaluation.md\n",
      "Processed: evolutionary-algorithm.md\n",
      "Processed: exascale.md\n",
      "Processed: exocortex.md\n",
      "Processed: expert-system.md\n",
      "Processed: explainability.md\n",
      "Processed: exploit-generator.md\n",
      "Processed: exponential-slope-blindness.md\n",
      "Processed: expressive-hidden-states.md\n",
      "Processed: fab.md\n",
      "Processed: fabless.md\n",
      "Processed: fact-checking-ai.md\n",
      "Processed: fairness-aware-machine-learning.md\n",
      "Processed: fast-takeoff.md\n",
      "Processed: fast-weights.md\n",
      "Processed: fcn-fully-convolutional-networks.md\n",
      "Processed: feature-design.md\n",
      "Processed: feature-extraction.md\n",
      "Processed: feature-importance.md\n",
      "Processed: federated-analytics.md\n",
      "Processed: federated-learning.md\n",
      "Processed: federated-training.md\n",
      "Processed: feed-forward.md\n",
      "Processed: few-shot.md\n",
      "Processed: fhe-fully-homomorphic-encryption.md\n",
      "Processed: findreplace-transformers.md\n",
      "Processed: fine-tuning.md\n",
      "Processed: flash-attention.md\n",
      "Processed: flexible-semantics.md\n",
      "Processed: flow-engineering.md\n",
      "Processed: foom.md\n",
      "Processed: forward-propagation.md\n",
      "Processed: foundation-model.md\n",
      "Processed: fourier-analysis.md\n",
      "Processed: fourier-features.md\n",
      "Processed: fourier-transform.md\n",
      "Processed: fpga-field-programmable-gate-array.md\n",
      "Processed: frame-problem.md\n",
      "Processed: frontier-models.md\n",
      "Processed: fsa-finite-state-automata.md\n",
      "Processed: fsdp-fully-sharded-data-parallel.md\n",
      "Processed: fsl-few-shot-learning.md\n",
      "Processed: full-sequence-diffusion.md\n",
      "Processed: function-approximation.md\n",
      "Processed: function-approximator.md\n",
      "Processed: functional-agi.md\n",
      "Processed: fuzzy-logic.md\n",
      "Processed: gabor-function.md\n",
      "Processed: gail-generative-adversarial-imitation-learning.md\n",
      "Processed: gan-generative-adversarial-network.md\n",
      "Processed: gat-graph-attention-network.md\n",
      "Processed: gating-mechanism.md\n",
      "Processed: gcc-general-computer-control.md\n",
      "Processed: gcn-graph-convolutional-networks.md\n",
      "Processed: general-world-model.md\n",
      "Processed: generalization.md\n",
      "Processed: generative-ai.md\n",
      "Processed: generative-model.md\n",
      "Processed: generative-workflow.md\n",
      "Processed: generative.md\n",
      "Processed: generator-verifier-gap.md\n",
      "Processed: geometric-deep-learning.md\n",
      "Processed: geometry-informed-neural-networks.md\n",
      "Processed: gflownet-generative-flow-networks.md\n",
      "Processed: gigo-garbage-in-garbage-out.md\n",
      "Processed: glu-gated-linear-unit.md\n",
      "Processed: gmm-gaussian-mixture-models.md\n",
      "Processed: gnn-graph-neural-networks.md\n",
      "Processed: goal.md\n",
      "Processed: god-in-a-box.md\n",
      "Processed: godel-code.md\n",
      "Processed: gofai-good-old-fashioned-ai.md\n",
      "Processed: gorilla-program.md\n",
      "Processed: gps-general-problem-solver.md\n",
      "Processed: gpt-generative-pre-trained-transformer.md\n",
      "Processed: gpu-graphics-processing-unit.md\n",
      "Processed: gpu-poor.md\n",
      "Processed: gqn-generative-query-network.md\n",
      "Processed: gradient-descent.md\n",
      "Processed: gradient-noise-scale.md\n",
      "Processed: graph-machine-learning.md\n",
      "Processed: graph-theory.md\n",
      "Processed: greedy-decoding.md\n",
      "Processed: grokking.md\n",
      "Processed: ground-truth.md\n",
      "Processed: groundedness.md\n",
      "Processed: grounding.md\n",
      "Processed: group-based-alignment.md\n",
      "Processed: guardrails.md\n",
      "Processed: hallucination.md\n",
      "Processed: hash-table.md\n",
      "Processed: hebbian-learning.md\n",
      "Processed: hessian-matrix.md\n",
      "Processed: heuristic-search-techniques.md\n",
      "Processed: hidden-layer.md\n",
      "Processed: hierarchical-planning.md\n",
      "Processed: hierarchy-of-generalizations.md\n",
      "Processed: hitl-human-in-the-loop.md\n",
      "Processed: hmi-human-machine-interface.md\n",
      "Processed: horizon.md\n",
      "Processed: hpc-high-performance-compute.md\n",
      "Processed: hpoc-human-point-of-contact.md\n",
      "Processed: human-level-ai.md\n",
      "Processed: hybrid-ai.md\n",
      "Processed: hyperdimensional-computing.md\n",
      "Processed: hypernetwork.md\n",
      "Processed: hyperparameter-tuning.md\n",
      "Processed: hyperparameter.md\n",
      "Processed: hyperplane.md\n",
      "Processed: hyperscalers.md\n",
      "Processed: hypersphere-based-transformer.md\n",
      "Processed: hyperspherical-representation-learning.md\n",
      "Processed: hypothesis-testing.md\n",
      "Processed: ifeval-instruction-following-eval.md\n",
      "Processed: image-recognition.md\n",
      "Processed: image-synthesis.md\n",
      "Processed: image-to-3d-model.md\n",
      "Processed: image-to-image-model.md\n",
      "Processed: image-to-text-model.md\n",
      "Processed: image-to-video-model.md\n",
      "Processed: imitation-learning.md\n",
      "Processed: implicit-reasoning.md\n",
      "Processed: in-context-learning.md\n",
      "Processed: incidental-polysemanticity.md\n",
      "Processed: indirect-manipulation.md\n",
      "Processed: inductive-bias.md\n",
      "Processed: inductive-prior.md\n",
      "Processed: inductive-reasoning.md\n",
      "Processed: inference-acceleration.md\n",
      "Processed: inference-time-reasoning.md\n",
      "Processed: inference.md\n",
      "Processed: infinite-context-window.md\n",
      "Processed: information-gap.md\n",
      "Processed: information-integration.md\n",
      "Processed: initialization.md\n",
      "Processed: instantiation.md\n",
      "Processed: instruction-following-model.md\n",
      "Processed: instruction-following.md\n",
      "Processed: instruction-tuning.md\n",
      "Processed: instrumental-convergence.md\n",
      "Processed: instrumentation.md\n",
      "Processed: intelligence-explosion.md\n",
      "Processed: intention.md\n",
      "Processed: interestingness.md\n",
      "Processed: internal-representation.md\n",
      "Processed: internet-scale.md\n",
      "Processed: interpretability.md\n",
      "Processed: intruder-dimension.md\n",
      "Processed: invariance.md\n",
      "Processed: inverse-problems.md\n",
      "Processed: io-influence-operations.md\n",
      "Processed: ir-information-retrieval.md\n",
      "Processed: irl-inverse-reinforcement-learning.md\n",
      "Processed: irreducibility.md\n",
      "Processed: itm-image-text-matching.md\n",
      "Processed: jagged-frontier.md\n",
      "Processed: jailbreaking.md\n",
      "Processed: jepa-joint-embedding-predictive-architecture.md\n",
      "Processed: jest-multimodal-contrastive-learning-with-joint-example-selection.md\n",
      "Processed: joint-embedding-architecture.md\n",
      "Processed: k-nn-k-nearest-neighbors.md\n",
      "Processed: kaggle-effect.md\n",
      "Processed: kaleidoscope-hypothesis.md\n",
      "Processed: kernel-method.md\n",
      "Processed: kl-kullbackleibler-divergence.md\n",
      "Processed: knowledge-graph.md\n",
      "Processed: knowledge-representation.md\n",
      "Processed: kv-key-value.md\n",
      "Processed: lam-large-action-model.md\n",
      "Processed: lambda-calculus.md\n",
      "Processed: laq-locally-adaptive-quantization.md\n",
      "Processed: latent-diffusion-backbone.md\n",
      "Processed: latent-space.md\n",
      "Processed: layer-normalization.md\n",
      "Processed: lda-latent-dirichlet-allocation.md\n",
      "Processed: learnability.md\n",
      "Processed: lemoine-effect.md\n",
      "Processed: lfms-liquid-foundation-models.md\n",
      "Processed: linear-algebra.md\n",
      "Processed: linear-complexity.md\n",
      "Processed: linear-separability.md\n",
      "Processed: lle-locally-linear-embedding.md\n",
      "Processed: llm-large-language-model.md\n",
      "Processed: lmn-large-nature-model.md\n",
      "Processed: ln-layer-normalization.md\n",
      "Processed: lnn-liquid-neural-network.md\n",
      "Processed: local-pooling.md\n",
      "Processed: local-weight-sharing.md\n",
      "Processed: log-likelihood.md\n",
      "Processed: logistic-regression.md\n",
      "Processed: logits.md\n",
      "Processed: long-context-modeling.md\n",
      "Processed: lora-low-rank-adaptation.md\n",
      "Processed: loss-function.md\n",
      "Processed: loss-landscape.md\n",
      "Processed: loss-optimization.md\n",
      "Processed: lossy-compression.md\n",
      "Processed: lost-in-the-middle.md\n",
      "Processed: lovelace-test.md\n",
      "Processed: low-bit-palletization.md\n",
      "Processed: lstm-long-short-term-memory.md\n",
      "Processed: ltpa-long-term-planning-agent.md\n",
      "Processed: lump-of-task-fallacy.md\n",
      "Processed: lvlms-large-vision-language-models.md\n",
      "Processed: machine-time.md\n",
      "Processed: machine-understanding.md\n",
      "Processed: machine-unlearning.md\n",
      "Processed: manifold-learning.md\n",
      "Processed: markov-blanket.md\n",
      "Processed: markov-chain.md\n",
      "Processed: mas-multi-agent-system.md\n",
      "Processed: masking.md\n",
      "Processed: matrix-models.md\n",
      "Processed: matrix-multiplication.md\n",
      "Processed: matryoshka-embedding.md\n",
      "Processed: max-pooling.md\n",
      "Processed: mcp-neuron.md\n",
      "Processed: mcts-monte-carlo-tree-search.md\n",
      "Processed: mdl-minimum-description-length.md\n",
      "Processed: mdo-multidomain-operations.md\n",
      "Processed: mdpo-mirror-descent-policy-optimization.md\n",
      "Processed: mechanistic-interpretability.md\n",
      "Processed: mechanistic-unlearning.md\n",
      "Processed: memory-extender.md\n",
      "Processed: memory-systems.md\n",
      "Processed: meta-classifier.md\n",
      "Processed: meta-learning.md\n",
      "Processed: meta-prompt.md\n",
      "Processed: meta-regressor.md\n",
      "Processed: metaheuristic.md\n",
      "Processed: mims-multiple-instance-learning-for-missing-annotations.md\n",
      "Processed: misuse.md\n",
      "Processed: mixture-map.md\n",
      "Processed: mixture-model.md\n",
      "Processed: ml-machine-learning.md\n",
      "Processed: mle-maximum-likelihood-estimation.md\n",
      "Processed: mllms-multimodal-large-language-models.md\n",
      "Processed: mlm-masked-language-modeling.md\n",
      "Processed: mlops-machine-learning-operations.md\n",
      "Processed: mlp-multilayer-perceptron.md\n",
      "Processed: mmlu-massive-multitask-language-understanding.md\n",
      "Processed: moat.md\n",
      "Processed: mode-collapse.md\n",
      "Processed: model-based-classifier.md\n",
      "Processed: model-collapse.md\n",
      "Processed: model-compression.md\n",
      "Processed: model-distillation.md\n",
      "Processed: model-drift-minimization.md\n",
      "Processed: model-drift.md\n",
      "Processed: model-garden.md\n",
      "Processed: model-layer.md\n",
      "Processed: model-level.md\n",
      "Processed: model-management.md\n",
      "Processed: model-stability.md\n",
      "Processed: moe-mixture-of-experts.md\n",
      "Processed: moloch.md\n",
      "Processed: monte-carlo-estimation.md\n",
      "Processed: moravec-s-paradox.md\n",
      "Processed: mortal-computation.md\n",
      "Processed: motor-learning.md\n",
      "Processed: move-37.md\n",
      "Processed: mpc-model-predictive-control.md\n",
      "Processed: mrl-matryoshka-representation-learning.md\n",
      "Processed: mtl-multi-task-learning.md\n",
      "Processed: multi-class-activation.md\n",
      "Processed: multi-headed-attention.md\n",
      "Processed: multi-token-prediction.md\n",
      "Processed: multiagent.md\n",
      "Processed: multimodal.md\n",
      "Processed: naive-bayesian-model.md\n",
      "Processed: narrow-ai.md\n",
      "Processed: nas-neural-architecture-search.md\n",
      "Processed: nationalization.md\n",
      "Processed: natural-language-problem.md\n",
      "Processed: natural-language.md\n",
      "Processed: negation-problem.md\n",
      "Processed: negative-feedback.md\n",
      "Processed: negative-references.md\n",
      "Processed: negative-utilitarianism.md\n",
      "Processed: nerf-neural-radiance-fields.md\n",
      "Processed: neural-network.md\n",
      "Processed: neurode.md\n",
      "Processed: neuroevolution.md\n",
      "Processed: neurogenesis.md\n",
      "Processed: neuromorphic-chips.md\n",
      "Processed: neurosymbolic-ai.md\n",
      "Processed: next-token-prediction.md\n",
      "Processed: next-word-prediction.md\n",
      "Processed: ngpt-normalized-transformer.md\n",
      "Processed: ngram.md\n",
      "Processed: nhi-non-human-intelligence.md\n",
      "Processed: nian-needle-in-a-needlestack.md\n",
      "Processed: nld-neural-lie-detectors.md\n",
      "Processed: nlp-natural-language-processing.md\n",
      "Processed: nlp-neuro-linguistic-programming.md\n",
      "Processed: nlu-natural-language-understanding.md\n",
      "Processed: nmf-non-negative-matrix-factorization.md\n",
      "Processed: noise.md\n",
      "Processed: non-contrastive.md\n",
      "Processed: nowcasting.md\n",
      "Processed: npc-non-player-character.md\n",
      "Processed: numerical-processing.md\n",
      "Processed: numerosity.md\n",
      "Processed: object-detection.md\n",
      "Processed: objective-function.md\n",
      "Processed: observability.md\n",
      "Processed: occams-razor.md\n",
      "Processed: on-the-fly-program-synthesis.md\n",
      "Processed: one-shot-learning.md\n",
      "Processed: ontology.md\n",
      "Processed: ood-out-of-distribution-behavior.md\n",
      "Processed: ooms-orders-of-magnitude.md\n",
      "Processed: open-ended-ai.md\n",
      "Processed: open-weights.md\n",
      "Processed: optimization-problem.md\n",
      "Processed: orchestration.md\n",
      "Processed: out-of-distribution.md\n",
      "Processed: output-verifier.md\n",
      "Processed: overfitting.md\n",
      "Processed: overhang.md\n",
      "Processed: overparameterization-regime.md\n",
      "Processed: overparameterized.md\n",
      "Processed: p-hacking.md\n",
      "Processed: panel-of-experts.md\n",
      "Processed: paperclip-maximizer.md\n",
      "Processed: parallelism.md\n",
      "Processed: parameter-size.md\n",
      "Processed: parameter-space.md\n",
      "Processed: parameter.md\n",
      "Processed: parameterized.md\n",
      "Processed: parametric-knowledge.md\n",
      "Processed: parametric-memory.md\n",
      "Processed: path-integration.md\n",
      "Processed: pdoom.md\n",
      "Processed: pds-psychological-depth-scale.md\n",
      "Processed: perceptron-convergence.md\n",
      "Processed: perceptron.md\n",
      "Processed: perceptual-domain.md\n",
      "Processed: perceptual-hash-algorithm.md\n",
      "Processed: performance-degradation.md\n",
      "Processed: permutation.md\n",
      "Processed: perplexity.md\n",
      "Processed: persistency.md\n",
      "Processed: personal-software.md\n",
      "Processed: persuasive-system.md\n",
      "Processed: pfgm-poisson-flow-generative-model.md\n",
      "Processed: phase-transition.md\n",
      "Processed: planetary-scale-system.md\n",
      "Processed: point-wise-feedforward-network.md\n",
      "Processed: policy-gradient-algorithm.md\n",
      "Processed: policy-gradient.md\n",
      "Processed: policy-guided-diffusion.md\n",
      "Processed: policy-learning.md\n",
      "Processed: policy-parameters.md\n",
      "Processed: polymathic-ai.md\n",
      "Processed: polymorphism.md\n",
      "Processed: positional-encoding.md\n",
      "Processed: post-training.md\n",
      "Processed: ppml-privacy-preserving-machine-learning.md\n",
      "Processed: ppo-proximal-policy-optimization.md\n",
      "Processed: pq-product-quantization.md\n",
      "Processed: precomputed-policy.md\n",
      "Processed: prediction-error.md\n",
      "Processed: prediction.md\n",
      "Processed: predictive-analytics.md\n",
      "Processed: predictive-processing.md\n",
      "Processed: preference-model.md\n",
      "Processed: pretrained-model.md\n",
      "Processed: price-per-token.md\n",
      "Processed: private-cloud-compute.md\n",
      "Processed: privileged-instructions.md\n",
      "Processed: probabilistic-inferencing.md\n",
      "Processed: probabilistic-programming.md\n",
      "Processed: process-reward-model.md\n",
      "Processed: program-induction.md\n",
      "Processed: proliferation-problem.md\n",
      "Processed: prompt-caching.md\n",
      "Processed: prompt-chaining.md\n",
      "Processed: prompt-engineering.md\n",
      "Processed: prompt-injection.md\n",
      "Processed: prompt.md\n",
      "Processed: promptocracy.md\n",
      "Processed: q-learning.md\n",
      "Processed: q-value.md\n",
      "Processed: qa-question-answering.md\n",
      "Processed: qml-quantum-machine-learning.md\n",
      "Processed: quantization.md\n",
      "Processed: quantum-computing.md\n",
      "Processed: query-flock.md\n",
      "Processed: query.md\n",
      "Processed: rag-retrieval-augmented-generation.md\n",
      "Processed: rainbow-teaming.md\n",
      "Processed: random-forest.md\n",
      "Processed: random-walk.md\n",
      "Processed: rank-fusion.md\n",
      "Processed: ravens-progressive-matrices.md\n",
      "Processed: rbms-restricted-boltzmann-machines.md\n",
      "Processed: react-reasonact.md\n",
      "Processed: reasoning-path.md\n",
      "Processed: recognition-model.md\n",
      "Processed: recommendation-systems.md\n",
      "Processed: recursive-self-improvement.md\n",
      "Processed: red-queen-effect.md\n",
      "Processed: red-teaming.md\n",
      "Processed: reflective-programming.md\n",
      "Processed: regime.md\n",
      "Processed: regression.md\n",
      "Processed: regularization.md\n",
      "Processed: rejection-sampling.md\n",
      "Processed: relu-rectified-linear-unit.md\n",
      "Processed: replaced-token-detection.md\n",
      "Processed: representation-engineering.md\n",
      "Processed: reranking.md\n",
      "Processed: residual-connections.md\n",
      "Processed: resnet-residual-network.md\n",
      "Processed: responsible-ai.md\n",
      "Processed: retrieval-based-model.md\n",
      "Processed: reversal-course.md\n",
      "Processed: reversal-curse.md\n",
      "Processed: reward-model-ensemble.md\n",
      "Processed: rfm-robotics-foundational-model.md\n",
      "Processed: rgm-renormalizing-generative-model.md\n",
      "Processed: rightsizing.md\n",
      "Processed: rl-reinforcement-learning.md\n",
      "Processed: rlaif-reinforcement-learning-with-ai-feedback.md\n",
      "Processed: rlhf-plus-plus.md\n",
      "Processed: rlhf-reinforcement-learning-from-human-feedback.md\n",
      "Processed: rnn-recurrent-neural-network.md\n",
      "Processed: robustness.md\n",
      "Processed: rokos-basilisk.md\n",
      "Processed: router.md\n",
      "Processed: sae-structural-adaptive-embeddings.md\n",
      "Processed: safety-net.md\n",
      "Processed: saif-secure-ai-framework.md\n",
      "Processed: salience.md\n",
      "Processed: sam-segment-anything-model.md\n",
      "Processed: sample-difficulty.md\n",
      "Processed: sample-efficiency.md\n",
      "Processed: sampling-algorithm.md\n",
      "Processed: sampling.md\n",
      "Processed: saturating-non-linearities.md\n",
      "Processed: saturation-effect.md\n",
      "Processed: scaffolding.md\n",
      "Processed: scalable-matmul-free-language-modeling.md\n",
      "Processed: scalar.md\n",
      "Processed: scale-separation.md\n",
      "Processed: scaling-hypothesis.md\n",
      "Processed: scaling-laws.md\n",
      "Processed: scientific-computing.md\n",
      "Processed: scm-continuous-time-consistency-model.md\n",
      "Processed: search-optimization.md\n",
      "Processed: search.md\n",
      "Processed: secure-enclave.md\n",
      "Processed: segmentation.md\n",
      "Processed: self-attention.md\n",
      "Processed: self-awareness.md\n",
      "Processed: self-correction.md\n",
      "Processed: self-reasoning-token.md\n",
      "Processed: self-speculative-decoding.md\n",
      "Processed: self-supervised-pretraining.md\n",
      "Processed: semantic-entropy.md\n",
      "Processed: semantic-indexing.md\n",
      "Processed: semantic-segmentation.md\n",
      "Processed: semi-supervised-learning.md\n",
      "Processed: sentiment-classifier.md\n",
      "Processed: seq2seq-sequence-to-sequence.md\n",
      "Processed: sequence-masking.md\n",
      "Processed: sequence-model.md\n",
      "Processed: sequence-prediction.md\n",
      "Processed: sequential-models.md\n",
      "Processed: shared-awareness.md\n",
      "Processed: shoggoth.md\n",
      "Processed: shors-algorithm.md\n",
      "Processed: siamese-network.md\n",
      "Processed: sil-simulator-in-the-loop.md\n",
      "Processed: silent-collapse.md\n",
      "Processed: silicon-based-intelligence.md\n",
      "Processed: sima-scalable-instructable-multiworld-agent.md\n",
      "Processed: similarity-computation.md\n",
      "Processed: similarity-masking.md\n",
      "Processed: similarity-search.md\n",
      "Processed: simulation.md\n",
      "Processed: singularity.md\n",
      "Processed: situational-models.md\n",
      "Processed: skill-differential.md\n",
      "Processed: slapa-self-learning-agent-for-performing-apis.md\n",
      "Processed: slm-sparse-linear-model.md\n",
      "Processed: slop.md\n",
      "Processed: snarc-stochastic-neural-analog-reinforcement-calculator.md\n",
      "Processed: snn-spiking-neural-network.md\n",
      "Processed: socratic-model.md\n",
      "Processed: softmax.md\n",
      "Processed: solomonoff-induction.md\n",
      "Processed: solution-space.md\n",
      "Processed: sota-state-of-the-art.md\n",
      "Processed: sovereign-ai.md\n",
      "Processed: spacetime-patches.md\n",
      "Processed: sparsability.md\n",
      "Processed: sparse-autoencoder.md\n",
      "Processed: sparse-coupling.md\n",
      "Processed: sparse-crosscoders.md\n",
      "Processed: sparsity.md\n",
      "Processed: spatial-autoencoder.md\n",
      "Processed: spatial-intelligence.md\n",
      "Processed: speculative-decoding.md\n",
      "Processed: speculative-edits.md\n",
      "Processed: speech-processing.md\n",
      "Processed: speech-to-image-model.md\n",
      "Processed: speech-to-speech-model.md\n",
      "Processed: speech-to-text-model.md\n",
      "Processed: speed-of-light-issues.md\n",
      "Processed: spillover.md\n",
      "Processed: ssf-stochastic-similarity-filter.md\n",
      "Processed: ssl-self-supervised-learning.md\n",
      "Processed: ssm-state-space-model.md\n",
      "Processed: stacking.md\n",
      "Processed: state-representation.md\n",
      "Processed: state-space-model.md\n",
      "Processed: stateful.md\n",
      "Processed: static-inference.md\n",
      "Processed: statistical-ai.md\n",
      "Processed: statistical-computing.md\n",
      "Processed: steerability.md\n",
      "Processed: stochastic-parrot.md\n",
      "Processed: stochastic.md\n",
      "Processed: straight-through-estimator.md\n",
      "Processed: streaming.md\n",
      "Processed: stride-length.md\n",
      "Processed: structured-data.md\n",
      "Processed: structured-generation.md\n",
      "Processed: structured-search.md\n",
      "Processed: subsymbolic-ai.md\n",
      "Processed: super-alignment.md\n",
      "Processed: super-prompting.md\n",
      "Processed: superintelligence.md\n",
      "Processed: supervised-classifier.md\n",
      "Processed: supervised-learning.md\n",
      "Processed: supervision.md\n",
      "Processed: surprisal.md\n",
      "Processed: surprise.md\n",
      "Processed: surrogate-objective.md\n",
      "Processed: svm-support-vector-machine.md\n",
      "Processed: swarm-intelligence.md\n",
      "Processed: symbolic-ai.md\n",
      "Processed: symbolic-computing.md\n",
      "Processed: symbolic-regression.md\n",
      "Processed: symmetry.md\n",
      "Processed: syntactic-templates.md\n",
      "Processed: synthetic-data-generation.md\n",
      "Processed: system-1-system-2.md\n",
      "Processed: system-prompt.md\n",
      "Processed: targeted-adversarial-examples.md\n",
      "Processed: task-environment.md\n",
      "Processed: tcn-temporal-convolutional-networks.md\n",
      "Processed: teacher-committee.md\n",
      "Processed: teacher-guided-rejection-sampling.md\n",
      "Processed: teacher-model.md\n",
      "Processed: tem-trusted-execution-monitor.md\n",
      "Processed: temperature.md\n",
      "Processed: tensor.md\n",
      "Processed: tensorflow.md\n",
      "Processed: tescreal.md\n",
      "Processed: test-time-compute.md\n",
      "Processed: text-to-action-model.md\n",
      "Processed: text-to-code-model.md\n",
      "Processed: text-to-image-model.md\n",
      "Processed: text-to-text-model.md\n",
      "Processed: tfidf-term-frequency-inverse-document-frequency.md\n",
      "Processed: thermodynamic-bayesian-inference.md\n",
      "Processed: thought-token.md\n",
      "Processed: three-laws-of-robotics.md\n",
      "Processed: token-processing.md\n",
      "Processed: token-speculation-techniques.md\n",
      "Processed: token.md\n",
      "Processed: tom-theory-of-mind.md\n",
      "Processed: top-k.md\n",
      "Processed: torment-nexus.md\n",
      "Processed: toy-diagram.md\n",
      "Processed: toy-program.md\n",
      "Processed: tpu-tensor-processing-units.md\n",
      "Processed: traceability.md\n",
      "Processed: training-compute.md\n",
      "Processed: training-cost.md\n",
      "Processed: training-data.md\n",
      "Processed: training-objective.md\n",
      "Processed: training.md\n",
      "Processed: trajectory-generation.md\n",
      "Processed: transfer-capability.md\n",
      "Processed: transfer-learning.md\n",
      "Processed: transformative-ai.md\n",
      "Processed: transformer-block.md\n",
      "Processed: transformer.md\n",
      "Processed: translational.md\n",
      "Processed: transposed-convolutional-layer.md\n",
      "Processed: tree-of-thought.md\n",
      "Processed: trigrams.md\n",
      "Processed: triple.md\n",
      "Processed: trl-transfer-reinforcement-learning.md\n",
      "Processed: trpo-trust-region-policy-optimization.md\n",
      "Processed: ttft-test-time-fine-tuning.md\n",
      "Processed: tts-text-to-speech.md\n",
      "Processed: ttt-test-time-training.md\n",
      "Processed: tunable-parameters.md\n",
      "Processed: turing-completeness.md\n",
      "Processed: turing-test.md\n",
      "Processed: uncensored-ai.md\n",
      "Processed: uncertainty-estimation.md\n",
      "Processed: uncertainty-reduction.md\n",
      "Processed: underfitting.md\n",
      "Processed: unembedding.md\n",
      "Processed: unhobbling.md\n",
      "Processed: unified-embedding.md\n",
      "Processed: universal-learning-algorithms.md\n",
      "Processed: universality.md\n",
      "Processed: unstructured-data.md\n",
      "Processed: unsupervised-learning.md\n",
      "Processed: unverifyability.md\n",
      "Processed: utility-function.md\n",
      "Processed: utm-universal-turing-machine.md\n",
      "Processed: vae-variational-autoencoders.md\n",
      "Processed: valence.md\n",
      "Processed: validation-data.md\n",
      "Processed: validation-metric.md\n",
      "Processed: value-matrix.md\n",
      "Processed: vanishing-gradient.md\n",
      "Processed: variance-reduction-techniques.md\n",
      "Processed: variance-scaling.md\n",
      "Processed: variational-free-energy.md\n",
      "Processed: vc-dimension-vapnik-chervonenkis.md\n",
      "Processed: vector-database.md\n",
      "Processed: vector-operation.md\n",
      "Processed: vectorization.md\n",
      "Processed: verification-system.md\n",
      "Processed: verifier-theory.md\n",
      "Processed: video-to-3d-model.md\n",
      "Processed: video-to-image-model.md\n",
      "Processed: video-to-text-model.md\n",
      "Processed: video-to-video-model.md\n",
      "Processed: vits-vision-transformers.md\n",
      "Processed: vlm-visual-language-model.md\n",
      "Processed: volumetric-ai.md\n",
      "Processed: vqa-visual-question-answering.md\n",
      "Processed: wait-calculation.md\n",
      "Processed: wake-sleep.md\n",
      "Processed: wavelet.md\n",
      "Processed: wbe-whole-brain-emulation.md\n",
      "Processed: weight-decay.md\n",
      "Processed: weight-initialization.md\n",
      "Processed: weight.md\n",
      "Processed: wham-world-and-human-action-model.md\n",
      "Processed: word-salad.md\n",
      "Processed: word-vector.md\n",
      "Processed: world-model.md\n",
      "Processed: xai-explainable-ai.md\n",
      "Processed: xaviers-initialization.md\n",
      "Processed: xenocognition.md\n",
      "Processed: xlstm.md\n",
      "Processed: xrx.md\n",
      "Processed: zero-shot-capability.md\n",
      "Processed: zsl-zero-shot-learning.md\n",
      "\n",
      "Results saved to /Users/kemi/Documents/GitHub/vocab/src/data/txyz-papers.json\n",
      "This batch: 920 files\n",
      "Total processed: 935\n",
      "Remaining unprocessed: 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
