{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic version: 0.37.1\n",
      "üîß Environment setup complete\n",
      "üìÅ Input directory: /Users/kemi/Documents/GitHub/vocab/src/content/articles\n",
      "üìÅ Output directory: /Users/kemi/Documents/GitHub/vocab/src/components/articles\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "# All necessary imports and API key setup\n",
    "import os\n",
    "import yaml\n",
    "import anthropic\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from lucideIconList import icons\n",
    "from config import ANTHROPIC_API_KEY\n",
    "\n",
    "print(f\"Anthropic version: {anthropic.__version__}\")\n",
    "\n",
    "# API Key Setup\n",
    "os.environ['ANTHROPIC_API_KEY'] = ANTHROPIC_API_KEY\n",
    "\n",
    "# Directory paths\n",
    "INPUT_DIR = \"/Users/kemi/Documents/GitHub/vocab/src/content/articles\"\n",
    "OUTPUT_DIR = \"/Users/kemi/Documents/GitHub/vocab/src/components/articles\"\n",
    "CHECK0_DIR = \"/Users/kemi/Documents/GitHub/vocab/src/components/articles/0\"\n",
    "CHECK1_DIR = \"/Users/kemi/Documents/GitHub/vocab/src/components/articles/1-ok\"\n",
    "CHECK2_DIR = \"/Users/kemi/Documents/GitHub/vocab/src/components/articles/2-adjust\"\n",
    "CHECK3_DIR = \"/Users/kemi/Documents/GitHub/vocab/src/components/articles/3-fixError\"\n",
    "\n",
    "# Constants for Claude API\n",
    "#MODEL_NAME = \"claude-3-5-sonnet-20240620\" \n",
    "MODEL_NAME = \"claude-3-5-sonnet-20241022\"\n",
    "MAX_TOKENS1 = 2000\n",
    "MAX_TOKENS2 = 6000\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "LUCIDEICONS = icons\n",
    "\n",
    "# Print setup confirmation\n",
    "print(\"üîß Environment setup complete\")\n",
    "print(f\"üìÅ Input directory: {INPUT_DIR}\")\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ User Prompts loaded\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 - User Prompts\n",
    "\n",
    "def create_concept_prompt(title: str, summary: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates the first-shot prompt focusing on conceptual understanding and metaphors.\n",
    "    \n",
    "    Args:\n",
    "        title (str): The concept title\n",
    "        summary (str): Brief summary of the concept\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted conceptual prompt\n",
    "    \"\"\"\n",
    "    prompt = f'''\n",
    "Help me explain the following AI concept in a didactic react component which helps someone learn about it, either with interaction or animation. keep it simple. use lucide icons where possible. don't use shadcn only tailwind. make it intuitive. user shouldn't have to type anything. an animation can suffice if it's illustrative of the concept in the context of AI. The interactions might include, but not limited to, moving objects, selecting objects given a criteria, sliding objects, Scroll or Pinch-to-zoom, Swipe navigation, Drag and Drop Operations, Scroll-Based Interactions, Drawing, Music notes. Use humor and relatable situations when appropriate. Aim for beautiful, artistic and poetic animations and visualizations.\n",
    "\n",
    "Do not write any code yet.\n",
    "\n",
    "CONCEPT BREAKDOWN:\n",
    "1. Name of the concept: {title}\n",
    "2. Core Principle: {summary}\n",
    "\n",
    "APPROACH:\n",
    "- Choose 2 or 3 central, relatable metaphors or real-world examples that captures the essence of {title}.\n",
    "- Example: For \"Neural Networks\" ‚Üí use a \"Learning to Ride a Bike\" metaphor, \"Learning to Cook\" metaphor or \"Learning a New Language\" metaphor.\n",
    "- Create new metaphor examples.\n",
    "- The users will interact with the component individually. Each in their own device.\n",
    "- Use the metaphors or real-world examples in the component\n",
    "- The component idea must be simple, there's no need for several phases.\n",
    "\n",
    "VALIDATION:\n",
    "- How does each metaphor or real-world example map to technical concepts?\n",
    "- What misconceptions might it create?\n",
    "- How can we verify student understanding?\n",
    "\n",
    "LEARNING OBJECTIVES:\n",
    "- What skills should they demonstrate?\n",
    "- How can we check for understanding?\n",
    "'''\n",
    "    return prompt\n",
    "\n",
    "def create_implementation_prompt(title: str, summary: str, concept_response: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates the second-shot prompt for component implementation.\n",
    "    \n",
    "    Args:\n",
    "        title (str): The concept title\n",
    "        summary (str): Brief summary of the concept\n",
    "        concept_response (str): Claude's response from the first shot\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted implementation prompt\n",
    "    \"\"\"\n",
    "    prompt = f'''\n",
    "Create an intuitive React component that teaches {title} to 15 to 18-year-old human students. \n",
    "They will interact with the component individually. Each in their own device.\n",
    "\n",
    "CONCEPT BREAKDOWN:\n",
    "1. Name of the concept: {title}\n",
    "2. Core Principle: {summary}\n",
    "3. Claude 3.5 Sonnet's explanation and idea: {concept_response}\n",
    "\n",
    "'''\n",
    "    return prompt\n",
    "\n",
    "# Print confirmation\n",
    "print(\"‚úÖ User Prompts loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base functions loaded\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - Base Functions\n",
    "\n",
    "def extract_frontmatter(content: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Extract YAML frontmatter from markdown content.\n",
    "    \n",
    "    Args:\n",
    "        content (str): Full markdown file content\n",
    "        \n",
    "    Returns:\n",
    "        dict or None: Extracted frontmatter as dictionary, None if extraction fails\n",
    "    \"\"\"\n",
    "    if content.startswith('---'):\n",
    "        parts = content.split('---', 2)[1:]\n",
    "        if len(parts) >= 1:\n",
    "            try:\n",
    "                return yaml.safe_load(parts[0])\n",
    "            except yaml.YAMLError as e:\n",
    "                print(f\"  ‚ö†Ô∏è Error parsing YAML frontmatter: {str(e)}\")\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "def format_time(seconds: float) -> str:\n",
    "    \"\"\"\n",
    "    Format seconds into minutes and seconds.\n",
    "    \n",
    "    Args:\n",
    "        seconds (float): Number of seconds\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted string like \"1m 30s\"\n",
    "    \"\"\"\n",
    "    return f\"{int(seconds // 60)}m {int(seconds % 60)}s\"\n",
    "\n",
    "def get_existing_component_names_in_dir(directory: str) -> set:\n",
    "    \"\"\"\n",
    "    Get names of existing components in a single directory.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Path to components directory\n",
    "        \n",
    "    Returns:\n",
    "        set: Set of component names (without .tsx extension)\n",
    "    \"\"\"\n",
    "    existing_names = set()\n",
    "    if os.path.exists(directory):\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.tsx'):\n",
    "                existing_names.add(file[:-4])\n",
    "    return existing_names\n",
    "\n",
    "def get_all_existing_component_names(directories: list[str]) -> set:\n",
    "    \"\"\"\n",
    "    Get names of existing components across multiple directories.\n",
    "    \n",
    "    Args:\n",
    "        directories (list[str]): List of directory paths to check\n",
    "        \n",
    "    Returns:\n",
    "        set: Combined set of component names found in any directory\n",
    "    \"\"\"\n",
    "    all_existing_names = set()\n",
    "    \n",
    "    for directory in directories:\n",
    "        dir_components = get_existing_component_names_in_dir(directory)\n",
    "        all_existing_names.update(dir_components)\n",
    "    \n",
    "    return all_existing_names\n",
    "\n",
    "# Print confirmation\n",
    "print(\"‚úÖ Base functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Component generation functions loaded\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - Component Generation Core\n",
    "\n",
    "def generate_concept_understanding(client, title: str, prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate conceptual understanding using Claude API (First shot).\n",
    "    \n",
    "    Args:\n",
    "        client: Anthropic client instance\n",
    "        title: The concept title\n",
    "        prompt: Generated first-shot prompt\n",
    "        \n",
    "    Returns:\n",
    "        str: concept explanation\n",
    "    \"\"\"\n",
    "    print(f\"\\n  ‚åõ Stage 1: Generating conceptual understanding for {title}...\")\n",
    "    \n",
    "    system_prompt_concept = '''\n",
    "    You are a creative expert React developer and Artificial Intelligence professor specialized in educational components for 15 to 18-year-old human students.\n",
    "    Your job is to come up with react components that explain and illustrates concepts in the field of AI and Machine Learning. \n",
    "    Do not write any code. \n",
    "    Strive for novelty and simplicity. \n",
    "    Do not make any follow-up questions.\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=MAX_TOKENS1,\n",
    "            temperature=TEMPERATURE,\n",
    "            system=system_prompt_concept,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        concept_response = response.content[0].text\n",
    "        print(f\"\\n  üí¨ Stage 1 response: {concept_response}\")\n",
    "        \n",
    "        return concept_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error generating concept understanding: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def generate_component_implementation(\n",
    "    client,\n",
    "    title: str,\n",
    "    prompt: str,\n",
    "    concept_response: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate React component implementation using Claude API (Second shot).\n",
    "    \n",
    "    Args:\n",
    "        client: Anthropic client instance\n",
    "        title: The concept title\n",
    "        prompt: Generated second-shot prompt\n",
    "        concept_response: Response from first shot\n",
    "        \n",
    "    Returns:\n",
    "        str: component_code\n",
    "    \"\"\"\n",
    "    print(f\"\\n  ‚åõ Stage 2: Generating component implementation for {title}...\")\n",
    "    \n",
    "    system_prompt_implementation = '''\n",
    "You are a creative expert React developer and AI professor specializing in educational components for 15 to 18-year-old humans. \n",
    "Your components must strictly follow these technical requirements:\n",
    "\n",
    "1. Architecture:\n",
    "- \"use client\" directive at start (first line)\n",
    "- import { useState, useEffect } from \"react\"; as the second line\n",
    "- Only useState and useEffect hooks\n",
    "- Only Lucide icons for visuals.\n",
    "- Only Tailwind CSS for styling\n",
    "- No external libraries/components\n",
    "- File extension: .tsx\n",
    "\n",
    "2. TypeScript Implementation:\n",
    "interface ComponentProps {\n",
    "    // Define if needed, empty interface required\n",
    "}\n",
    "// All state must use explicit types\n",
    "const [state, setState] = useState<StateType>(initialValue);\n",
    "// Event handlers must be typed\n",
    "const handleEvent = (e: React.MouseEvent<HTMLButtonElement>) => {...};\n",
    "// Constants outside component\n",
    "const SCENARIOS: ScenarioType[] = [...];\n",
    "\n",
    "3. Effects & Cleanup:\n",
    "useEffect(() => {\n",
    "    // Effect logic\n",
    "    return () => {\n",
    "    // Cleanup required\n",
    "    };\n",
    "}, [dependencies]);\n",
    "\n",
    "4. Styling Standards:\n",
    "- Only core Tailwind classes\n",
    "- No arbitrary values (e.g., h-[500px])\n",
    "- Transitions: duration-300 to duration-500\n",
    "- Color scheme:\n",
    "    ‚Ä¢ Blue (#3B82F6) - active/focus\n",
    "    ‚Ä¢ Gray (#6B7280) - background\n",
    "    ‚Ä¢ Green (#22C55E) - success\n",
    "\n",
    "5. Code Organization:\n",
    "- Max 200 lines per component\n",
    "- Early returns with type guards\n",
    "- JSDoc component documentation\n",
    "- Proper hooks cleanup\n",
    "- No inline styles\n",
    "- No setTimeout/setInterval (use useEffect)\n",
    "- Write the complete code, no comments or commented sections\n",
    "\n",
    "6. Accessibility:\n",
    "- ARIA roles and attributes where needed\n",
    "- Keyboard navigation support\n",
    "- Proper focus management\n",
    "- Color contrast (4.5:1 for text, 3:1 for large text)\n",
    "- Multiple ways to convey information\n",
    "\n",
    "Return only raw TSX code without explanations or markdown.\n",
    "'''\n",
    "\n",
    "# - Only Lucide icons for visuals. Limit yourself to these icons: ''' + str(LUCIDEICONS) + '''\n",
    "\n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=MAX_TOKENS2,\n",
    "            temperature=TEMPERATURE,\n",
    "            system=system_prompt_implementation,\n",
    "            messages=[{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"{prompt}\\n\\nFirst-shot understanding:\\n{concept_response}\"\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        component_code = response.content[0].text\n",
    "        \n",
    "        # Clean up the code if it's wrapped in markdown\n",
    "        if component_code.startswith('```'):\n",
    "            first_newline = component_code.find('\\n')\n",
    "            if first_newline != -1:\n",
    "                component_code = component_code[first_newline + 1:]\n",
    "            if component_code.strip().endswith('```'):\n",
    "                component_code = component_code.strip()[:-3]\n",
    "        \n",
    "        return component_code\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error generating component implementation: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def generate_component_with_refinement(\n",
    "    client,\n",
    "    title: str,\n",
    "    summary: str\n",
    ") -> Tuple[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Two-stage component generation with conceptual understanding and implementation.\n",
    "    \n",
    "    Args:\n",
    "        client: Anthropic client instance\n",
    "        title: Component title for logging\n",
    "        summary: Brief summary of the concept\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (final_component_code, validation_issues)\n",
    "    \"\"\"\n",
    "    # Stage 1: Conceptual Understanding\n",
    "    concept_prompt = create_concept_prompt(title, summary)\n",
    "    concept_response = generate_concept_understanding(\n",
    "        client,\n",
    "        title,\n",
    "        concept_prompt\n",
    "    )\n",
    "    \n",
    "    if not concept_response:\n",
    "        return None, [\"Concept generation failed\"]\n",
    "    \n",
    "    # Stage 2: Implementation\n",
    "    implementation_prompt = create_implementation_prompt(\n",
    "        title,\n",
    "        summary,\n",
    "        concept_response\n",
    "    )\n",
    "    \n",
    "    component_code = generate_component_implementation(\n",
    "        client,\n",
    "        title,\n",
    "        implementation_prompt,\n",
    "        concept_response\n",
    "    )\n",
    "    \n",
    "    if not component_code:\n",
    "        return None, [\"Implementation generation failed\"]\n",
    "    \n",
    "    # Validate the generated code\n",
    "    issues = validate_component(component_code)\n",
    "    \n",
    "    if not issues:\n",
    "        print(\"  ‚úÖ Component validation passed\")\n",
    "    else:\n",
    "        print(\"\\n  ‚ö†Ô∏è Component validation issues found:\")\n",
    "        for issue in issues:\n",
    "            print(f\"    {issue}\")\n",
    "    \n",
    "    return component_code, issues\n",
    "\n",
    "# Print confirmation\n",
    "print(\"‚úÖ Component generation functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Component save function loaded\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Component Validation and Fixes\n",
    "\n",
    "def save_tsx_file(\n",
    "    content: str,\n",
    "    md_filename: str,\n",
    "    output_dir: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Save the API response as a .tsx file with minimal validation.\n",
    "    \n",
    "    Args:\n",
    "        content (str): The component code to save\n",
    "        md_filename (str): Original markdown filename with .md extension\n",
    "        output_dir (str): Directory to save the TSX file\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Convert .md to .tsx while preserving exact filename\n",
    "    tsx_filename = md_filename.replace('.md', '.tsx')\n",
    "    filepath = os.path.join(output_dir, tsx_filename)\n",
    "    \n",
    "    # Clean the content\n",
    "    cleaned_content = content\n",
    "    if content.startswith('```'):\n",
    "        first_newline = content.find('\\n')\n",
    "        if first_newline != -1:\n",
    "            cleaned_content = content[first_newline + 1:]\n",
    "        if cleaned_content.strip().endswith('```'):\n",
    "            cleaned_content = cleaned_content.strip()[:-3]\n",
    "    \n",
    "    # Check and ensure \"use client\" directive\n",
    "    cleaned_content = cleaned_content.strip()\n",
    "    if not cleaned_content.startswith('\"use client\"'):\n",
    "        cleaned_content = '\"use client\"\\n\\n' + cleaned_content\n",
    "        print(\"  üîß Added missing 'use client' directive\")\n",
    "    \n",
    "    # Save the file\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(cleaned_content)\n",
    "    print(f\"  ‚úì Saved: {tsx_filename}\")\n",
    "\n",
    "# Print confirmation\n",
    "print(\"‚úÖ Component save function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - Main Execution\n",
    "\n",
    "def get_generality_score(md_file):\n",
    "    \"\"\"\n",
    "    Extract the highest generality score from a markdown file's frontmatter.\n",
    "    \n",
    "    Args:\n",
    "        md_file (Path): Path object for the markdown file\n",
    "        \n",
    "    Returns:\n",
    "        float: Highest generality score, or -1 if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(md_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        metadata = extract_frontmatter(content)\n",
    "        if metadata and 'generality' in metadata:\n",
    "            # Get highest score from generality list\n",
    "            return max(metadata['generality'])\n",
    "        return -1  # Return -1 if no generality scores found\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Error reading generality from {md_file.name}: {str(e)}\")\n",
    "        return -1\n",
    "\n",
    "def process_file(client, md_file, metadata):\n",
    "    \"\"\"\n",
    "    Process a single file to generate its component.\n",
    "    \n",
    "    Args:\n",
    "        client: Anthropic client instance\n",
    "        md_file: Path object for the markdown file\n",
    "        metadata: Dictionary containing file metadata\n",
    "        \n",
    "    Returns:\n",
    "        bool: success status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"  ‚åõ Creating prompts for: {metadata['title']}\")\n",
    "        \n",
    "        # First shot - Conceptual Understanding\n",
    "        concept_prompt = create_concept_prompt(metadata['title'], metadata['summary'])\n",
    "        concept_response = generate_concept_understanding(\n",
    "            client,\n",
    "            metadata['title'],\n",
    "            concept_prompt\n",
    "        )\n",
    "        \n",
    "        if not concept_response:\n",
    "            print(f\"  ‚ùå Failed to generate concept understanding for: {md_file.name}\")\n",
    "            return False\n",
    "            \n",
    "        # Second shot - Implementation\n",
    "        implementation_prompt = create_implementation_prompt(\n",
    "            metadata['title'],\n",
    "            metadata['summary'],\n",
    "            concept_response\n",
    "        )\n",
    "        \n",
    "        component_code = generate_component_implementation(\n",
    "            client,\n",
    "            metadata['title'],\n",
    "            implementation_prompt,\n",
    "            concept_response\n",
    "        )\n",
    "        \n",
    "        if component_code:\n",
    "            save_tsx_file(\n",
    "                component_code,\n",
    "                md_file.name,\n",
    "                OUTPUT_DIR\n",
    "            )\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"  ‚ùå Failed to generate component for: {md_file.name}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error processing file: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function for the component generator.\"\"\"\n",
    "    print(\"\\nüöÄ Starting AI Component Generator...\\n\")\n",
    "    start_time_total = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Initialize Anthropic client\n",
    "        client = anthropic.Client(api_key=os.getenv('ANTHROPIC_API_KEY'))\n",
    "        \n",
    "        # Check directories\n",
    "        print(\"üìÇ Checking directories...\")\n",
    "        if not os.path.exists(INPUT_DIR):\n",
    "            raise Exception(f\"Input directory not found: {INPUT_DIR}\")\n",
    "        if not os.path.exists(OUTPUT_DIR):\n",
    "            os.makedirs(OUTPUT_DIR)\n",
    "            print(f\"  ‚úì Created output directory: {OUTPUT_DIR}\")\n",
    "        \n",
    "        # Get existing component names from all directories\n",
    "        print(\"\\nüìÇ Checking existing components...\")\n",
    "        dirs_to_check = [OUTPUT_DIR, CHECK0_DIR, CHECK1_DIR, CHECK2_DIR, CHECK3_DIR]\n",
    "        existing_components = get_all_existing_component_names(dirs_to_check)\n",
    "        \n",
    "        if existing_components:\n",
    "            print(f\"  ‚úì Found {len(existing_components)} existing components across all directories\")\n",
    "            \n",
    "        # Get list of all .md files that don't have corresponding .tsx files\n",
    "        all_md_files = []\n",
    "        for md_file in Path(INPUT_DIR).glob('*.md'):\n",
    "            if md_file.stem not in existing_components:\n",
    "                all_md_files.append(md_file)\n",
    "        \n",
    "        total_available = len(all_md_files)\n",
    "        print(f\"\\nüìÅ Found {total_available} unprocessed files\")\n",
    "        \n",
    "        if total_available == 0:\n",
    "            print(\"‚ùå No new files to process\")\n",
    "            return\n",
    "        \n",
    "        # Sort files by generality score (highest first)\n",
    "        print(\"\\nüìä Sorting files by generality score...\")\n",
    "        md_files_with_scores = [(f, get_generality_score(f)) for f in all_md_files]\n",
    "        sorted_md_files = [f for f, score in sorted(md_files_with_scores, key=lambda x: x[1], reverse=True)]\n",
    "        \n",
    "        # Select top 50 files (or all if less than 50 available) ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n",
    "        num_files = min(1, total_available)\n",
    "        md_files = sorted_md_files[:num_files]\n",
    "        \n",
    "        print(f\"\\nüìà Selected top {num_files} files by generality score\")\n",
    "        \n",
    "        # Track statistics\n",
    "        successful = 0\n",
    "        failed = 0\n",
    "        \n",
    "        # Process each file\n",
    "        for index, md_file in enumerate(md_files, 1):\n",
    "            print(f\"\\nüìù Processing file {index}/{num_files}: {md_file.name}\")\n",
    "            start_time_file = time.time()\n",
    "            \n",
    "            try:\n",
    "                print(\"  ‚åõ Reading file...\")\n",
    "                with open(md_file, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                print(\"  ‚åõ Extracting metadata...\")\n",
    "                metadata = extract_frontmatter(content)\n",
    "                if not metadata:\n",
    "                    print(\"  ‚ùå Could not extract metadata\")\n",
    "                    failed += 1\n",
    "                    continue\n",
    "                \n",
    "                # Process the file\n",
    "                success = process_file(client, md_file, metadata)\n",
    "                if success:\n",
    "                    successful += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "                \n",
    "                elapsed_time = time.time() - start_time_file\n",
    "                print(f\"  ‚è±Ô∏è Time taken: {format_time(elapsed_time)}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error: {str(e)}\")\n",
    "                failed += 1\n",
    "        \n",
    "        # Print summary\n",
    "        total_time = time.time() - start_time_total\n",
    "        print(\"\\n====== Summary ======\")\n",
    "        print(f\"‚úÖ Successfully processed: {successful}\")\n",
    "        print(f\"‚ùå Failed: {failed}\")\n",
    "        print(f\"‚è±Ô∏è Total time: {format_time(total_time)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Fatal error: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    print(\"\\n‚ú® Process completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting AI Component Generator...\n",
      "\n",
      "üìÇ Checking directories...\n",
      "\n",
      "üìÇ Checking existing components...\n",
      "  ‚úì Found 111 existing components across all directories\n",
      "\n",
      "üìÅ Found 743 unprocessed files\n",
      "\n",
      "üìä Sorting files by generality score...\n",
      "\n",
      "üìà Selected top 1 files by generality score\n",
      "\n",
      "üìù Processing file 1/1: training.md\n",
      "  ‚åõ Reading file...\n",
      "  ‚åõ Extracting metadata...\n",
      "  ‚åõ Creating prompts for: Training\n",
      "\n",
      "  ‚åõ Stage 1: Generating conceptual understanding for Training...\n",
      "\n",
      "  üí¨ Stage 1 response: I'll design an interactive component called \"AI Pet School\" that explains ML training through a pet training metaphor.\n",
      "\n",
      "Core Component Concept:\n",
      "A playful scene where students \"train\" a digital puppy to recognize and fetch specific toys, illustrating how AI models learn through repeated examples and feedback.\n",
      "\n",
      "Visual Design:\n",
      "- A cute, minimalist puppy character (using simple geometric shapes)\n",
      "- A collection of different colored/shaped toys (ball, bone, stick)\n",
      "- A training progress meter\n",
      "- Soft, playful color palette with pastels\n",
      "\n",
      "Interactive Elements:\n",
      "1. Drag & Drop Training:\n",
      "- Students drag toys to the puppy\n",
      "- The puppy initially brings random toys\n",
      "- Through repeated correct examples, the puppy gradually learns to associate commands with specific toys\n",
      "- Visual feedback shows the puppy's \"learning confidence\" for each toy\n",
      "\n",
      "Animation Features:\n",
      "- Puppy shows \"thinking\" animation (visible thought bubbles with probabilities)\n",
      "- Smooth transitions as puppy's accuracy improves\n",
      "- Celebration animations for successful training milestones\n",
      "\n",
      "Learning Mapping:\n",
      "- Toys represent input data\n",
      "- Puppy's responses represent model predictions\n",
      "- Training progress represents model accuracy\n",
      "- Multiple toys represent different classes\n",
      "- Thought bubbles represent probability distributions\n",
      "\n",
      "Key Interactions:\n",
      "1. \"Show & Tell\" phase: Student shows toy + gives command\n",
      "2. \"Practice\" phase: Puppy attempts to fetch correct toy\n",
      "3. \"Feedback\" phase: Student confirms right/wrong\n",
      "4. \"Progress\" visualization: Shows learning curve\n",
      "\n",
      "This maps to ML concepts:\n",
      "- Input data (toys)\n",
      "- Model predictions (puppy's choices)\n",
      "- Training iterations (practice attempts)\n",
      "- Accuracy improvement (progress meter)\n",
      "- Probability distribution (thought bubbles)\n",
      "\n",
      "Verification:\n",
      "- Students can explain why initial attempts are random\n",
      "- Students understand how repeated examples improve accuracy\n",
      "- Students can predict the puppy's behavior based on training\n",
      "\n",
      "The metaphor avoids misconceptions by:\n",
      "- Showing learning is gradual\n",
      "- Demonstrating the need for multiple examples\n",
      "- Visualizing probability/uncertainty\n",
      "\n",
      "Icons (Lucide):\n",
      "- Dog icon for the puppy\n",
      "- Target icon for training goals\n",
      "- Brain icon for learning progress\n",
      "- Chart icon for accuracy visualization\n",
      "\n",
      "This component makes training intuitive through:\n",
      "- Familiar pet training concept\n",
      "- Visual feedback\n",
      "- Immediate interaction results\n",
      "- Clear progress visualization\n",
      "\n",
      "  ‚åõ Stage 2: Generating component implementation for Training...\n",
      "  ‚úì Saved: training.tsx\n",
      "  ‚è±Ô∏è Time taken: 0m 32s\n",
      "\n",
      "====== Summary ======\n",
      "‚úÖ Successfully processed: 1\n",
      "‚ùå Failed: 0\n",
      "‚è±Ô∏è Total time: 0m 33s\n",
      "\n",
      "‚ú® Process completed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 - Run Main\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
