---
category: CORE, DATA
slug: top-k
summary: Method in ML and information retrieval where the system selects the k most relevant or highest-scoring items from a larger set of predictions or results.
title: Top-K
---

- **Detailed Explanation**: In AI, _top-k_ is often used in the context of ranking, recommendation, and search algorithms to retrieve the most relevant k items from a model’s output. For example, in natural language processing (NLP) models like transformers, the _top-k_ sampling technique is used in text generation, where the model samples from the k most probable tokens at each step, increasing the diversity and coherence of the generated text. This is crucial in tasks like search engines, recommender systems, and classification tasks, where returning only the most relevant subset improves both efficiency and user experience. By limiting the output to k items, models can avoid overwhelming users with too much information and focus on precision.
    
- **Historical Overview**: The concept of _top-k_ emerged in the 1990s, gaining traction in the early 2000s with the rise of large-scale search and ranking systems like Google. It became especially important as AI-based recommendation systems and search algorithms became mainstream in the 2010s.
    
- **Key Contributors**: The development of the _top-k_ concept is closely tied to advancements in information retrieval and ranking theory, with contributions from AI and data science researchers, including experts from companies like Google and Amazon who pioneered large-scale recommender systems and search algorithms.